{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040f57ec-fb76-4b67-82b0-efd165313173",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e28817-7adc-45a4-ad9e-ccfd5a44863c",
   "metadata": {},
   "source": [
    "**Clustering** is an unsupervised learning task (no response variable labels or values) where we are trying to find groups in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e9436-7d88-47e7-98fa-4abc19b1e5cc",
   "metadata": {},
   "source": [
    "**WSSD: Within-cluster Sum of Squared Distances**. Lower WSSD means better clustering (clusters are tightly packed together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba2326-67ac-4938-9404-6c831ee7feeb",
   "metadata": {},
   "source": [
    "**K Means Algorithm:** Groups the unlabelled data into k clusters via the following step:\n",
    "1) Random initialisation of clusters\n",
    "2) **Center update**: Compute the center of each cluster.\n",
    "3) **Label update**: Reassign each data point to the cluster with the nearest center.\n",
    "4) Repeat 2) and 3) until no clusters change /no label assignments change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb652e3c-e5c0-487b-a23f-68ae35ac2cb6",
   "metadata": {},
   "source": [
    "Generally, we use a set number of random restarts (nstart argument). Sometime, on a particular initialisation, the k-means algorithm gets stuck in a bad solution. By using a few restarts, we can just simply repeat the algorithm with a different initialisation and pick the best clustering (if one exists). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354ac15-507e-4209-9df1-63939748b506",
   "metadata": {},
   "source": [
    "**Choosing K:** Choose K at the elbow on an elbow plot (total WSSD vs K). K smaller than this would result in too few clusters, so groups are not visible in the data. Conversely, if K is too large, then there are too many subgroups which means important patterns or clusters are not visible. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b2766-b0a2-413c-ad36-24a91df0089b",
   "metadata": {},
   "source": [
    "**Standardising the data for K-Means** Variables with a large scale will have a much larger effect on deciding cluster assignment than variables with a small scale. This is because K-Means uses euclidean distance to compute the distance between a point and the center of a cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f016cf-53a6-4d3a-9c9c-43d75dc6991e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
